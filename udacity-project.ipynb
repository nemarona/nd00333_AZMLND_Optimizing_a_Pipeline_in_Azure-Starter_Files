{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Setup"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Workspace, Experiment\n",
        "\n",
        "ws = Workspace.from_config()\n",
        "exp = Experiment(workspace=ws, name=\"udacity-project\")\n",
        "\n",
        "print('Workspace name: ' + ws.name, \n",
        "      'Azure region: ' + ws.location, \n",
        "      'Subscription id: ' + ws.subscription_id, \n",
        "      'Resource group: ' + ws.resource_group, sep = '\\n')\n",
        "\n",
        "run = exp.start_logging()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Workspace name: quick-starts-ws-235168\nAzure region: eastus2\nSubscription id: 9a7511b8-150f-4a58-8528-3e7d50216c31\nResource group: aml-quickstarts-235168\n"
        }
      ],
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1686065651462
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core.compute import ComputeTarget, AmlCompute\n",
        "from azureml.core.compute_target import ComputeTargetException\n",
        "\n",
        "cluster_name = \"eduProject1\"\n",
        "\n",
        "# TODO: Create compute cluster\n",
        "# Use vm_size = \"Standard_D2_V2\" in your provisioning configuration.\n",
        "# max_nodes should be no greater than 4.\n",
        "\n",
        "### YOUR CODE HERE ###\n",
        "try:\n",
        "    cluster = ComputeTarget(ws, cluster_name)\n",
        "    print(\"Found existing cluster!\")\n",
        "except ComputeTargetException:\n",
        "    print(\"No cluster found, creating one...\")\n",
        "    compute_config = AmlCompute.provisioning_configuration(vm_size=\"STANDARD_D2_V2\", min_nodes=0, max_nodes=4)\n",
        "    cluster = ComputeTarget.create(ws, cluster_name, compute_config)\n",
        "    cluster.wait_for_completion(show_output=True)\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Found existing cluster!\n"
        }
      ],
      "execution_count": 2,
      "metadata": {
        "gather": {
          "logged": 1686065662092
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## HyperDrive"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.widgets import RunDetails\n",
        "from azureml.train.sklearn import SKLearn\n",
        "from azureml.train.hyperdrive.run import PrimaryMetricGoal\n",
        "from azureml.train.hyperdrive.policy import BanditPolicy\n",
        "from azureml.train.hyperdrive.sampling import RandomParameterSampling\n",
        "from azureml.train.hyperdrive.runconfig import HyperDriveConfig\n",
        "from azureml.train.hyperdrive.parameter_expressions import choice, uniform\n",
        "from azureml.core import Environment, ScriptRunConfig\n",
        "import os\n",
        "\n",
        "# Specify parameter sampler\n",
        "ps = RandomParameterSampling({\n",
        "    \"--C\": uniform(0.01, 1.0),\n",
        "    \"--max-iter\": choice(10, 20, 50, 100, 200)\n",
        "})\n",
        "\n",
        "# Specify a Policy\n",
        "policy = BanditPolicy(evaluation_interval=5, slack_factor=0.1)\n",
        "\n",
        "if \"training\" not in os.listdir():\n",
        "    os.mkdir(\"./training\")\n",
        "\n",
        "# Setup environment for your training run\n",
        "sklearn_env = Environment.from_conda_specification(name='sklearn-env', file_path='conda_dependencies.yml')\n",
        "\n",
        "# Create a ScriptRunConfig Object to specify the configuration details of your training job\n",
        "# Using SKLearn because ScriptRunConfig doesn't seem to work\n",
        "# src = ### YOUR CODE HERE ###\n",
        "compute_target = ws.compute_targets[cluster_name]\n",
        "estimator = SKLearn(source_directory=\".\", compute_target=compute_target, entry_script=\"train.py\")\n",
        "\n",
        "# Create a HyperDriveConfig using the src object, hyperparameter sampler, and policy.\n",
        "# hyperdrive_config = ### YOUR CODE HERE ###\n",
        "hyperdrive_config = HyperDriveConfig(\n",
        "    estimator=estimator,\n",
        "    hyperparameter_sampling=ps,\n",
        "    policy=policy,\n",
        "    primary_metric_name=\"Accuracy\",\n",
        "    primary_metric_goal=PrimaryMetricGoal.MAXIMIZE,\n",
        "    max_total_runs=5\n",
        ")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "'SKLearn' estimator is deprecated. Please use 'ScriptRunConfig' from 'azureml.core.script_run_config' with your own defined environment or the AzureML-Tutorial curated environment.\n"
        }
      ],
      "execution_count": 3,
      "metadata": {
        "gather": {
          "logged": 1686065708134
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Submit your hyperdrive run to the experiment and show run details with the widget.\n",
        "\n",
        "### YOUR CODE HERE ###\n",
        "hyperdrive_run = exp.submit(config=hyperdrive_config)\n",
        "RunDetails(hyperdrive_run).show()\n",
        "hyperdrive_run.wait_for_completion(show_output=True)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "WARNING:root:If 'script' has been provided here and a script file name has been specified in 'run_config', 'script' provided in ScriptRunConfig initialization will take precedence.\n"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "_HyperDriveWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': False, 'log_level': 'INFO'â€¦",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "034be1d8afec482c9ccba5be7e677bc4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/aml.mini.widget.v1": "{\"status\": \"Failed\", \"workbench_run_details_uri\": \"https://ml.azure.com/runs/HD_996f83d1-87a6-47f0-bbcf-e14004fb928c?wsid=/subscriptions/9a7511b8-150f-4a58-8528-3e7d50216c31/resourcegroups/aml-quickstarts-235168/workspaces/quick-starts-ws-235168&tid=660b3398-b80e-49d2-bc5b-ac1dc93b5254\", \"run_id\": \"HD_996f83d1-87a6-47f0-bbcf-e14004fb928c\", \"run_properties\": {\"run_id\": \"HD_996f83d1-87a6-47f0-bbcf-e14004fb928c\", \"created_utc\": \"2023-06-06T15:36:51.04113Z\", \"properties\": {\"primary_metric_config\": \"{\\\"name\\\":\\\"Accuracy\\\",\\\"goal\\\":\\\"maximize\\\"}\", \"resume_from\": \"null\", \"runTemplate\": \"HyperDrive\", \"azureml.runsource\": \"hyperdrive\", \"platform\": \"AML\", \"ContentSnapshotId\": \"dfc2537b-ca59-446a-a260-abfc5671e6b9\", \"user_agent\": \"python/3.8.5 (Linux-5.15.0-1035-azure-x86_64-with-glibc2.10) msrest/0.7.1 Hyperdrive.Service/1.0.0 Hyperdrive.SDK/core.1.49.0\", \"space_size\": \"infinite_space_size\"}, \"tags\": {\"_aml_system_max_concurrent_jobs\": \"5\", \"_aml_system_max_total_jobs\": \"5\", \"_aml_system_max_duration_minutes\": \"10080\", \"_aml_system_policy_config\": \"{\\\"name\\\":\\\"Bandit\\\",\\\"properties\\\":{\\\"evaluation_interval\\\":5,\\\"delay_evaluation\\\":0,\\\"slack_factor\\\":0.1}}\", \"_aml_system_generator_config\": \"{\\\"name\\\":\\\"RANDOM\\\",\\\"parameter_space\\\":{\\\"--C\\\":[\\\"uniform\\\",[0.01,1.0]],\\\"--max-iter\\\":[\\\"choice\\\",[[10,20,50,100,200]]]},\\\"properties\\\":null}\", \"_aml_system_primary_metric_config\": \"{\\\"name\\\":\\\"Accuracy\\\",\\\"goal\\\":\\\"maximize\\\"}\", \"_aml_system_platform_config\": \"{\\\"ServiceAddress\\\":\\\"https://eastus2.experiments.azureml.net\\\",\\\"SubscriptionId\\\":\\\"9a7511b8-150f-4a58-8528-3e7d50216c31\\\",\\\"ResourceGroupName\\\":\\\"aml-quickstarts-235168\\\",\\\"WorkspaceName\\\":\\\"quick-starts-ws-235168\\\",\\\"ExperimentName\\\":\\\"udacity-project\\\",\\\"Definition\\\":{\\\"Configuration\\\":null,\\\"Attribution\\\":null,\\\"TelemetryValues\\\":{\\\"amlClientType\\\":\\\"azureml-sdk-train\\\",\\\"amlClientModule\\\":\\\"[Scrubbed]\\\",\\\"amlClientFunction\\\":\\\"[Scrubbed]\\\",\\\"tenantId\\\":\\\"660b3398-b80e-49d2-bc5b-ac1dc93b5254\\\",\\\"amlClientRequestId\\\":\\\"6d388966-01c6-4694-aeca-fd7174ba219c\\\",\\\"amlClientSessionId\\\":\\\"8eee2bb8-a926-46b2-98ea-7f5106bb5768\\\",\\\"subscriptionId\\\":\\\"9a7511b8-150f-4a58-8528-3e7d50216c31\\\",\\\"estimator\\\":\\\"SKLearn\\\",\\\"samplingMethod\\\":\\\"RANDOM\\\",\\\"terminationPolicy\\\":\\\"Bandit\\\",\\\"primaryMetricGoal\\\":\\\"maximize\\\",\\\"maxTotalRuns\\\":5,\\\"maxConcurrentRuns\\\":5,\\\"maxDurationMinutes\\\":10080,\\\"vmSize\\\":null},\\\"Overrides\\\":{\\\"Script\\\":\\\"train.py\\\",\\\"Command\\\":\\\"\\\",\\\"UseAbsolutePath\\\":false,\\\"Arguments\\\":[],\\\"SourceDirectoryDataStore\\\":null,\\\"Framework\\\":0,\\\"Communicator\\\":0,\\\"Target\\\":\\\"eduProject1\\\",\\\"DataReferences\\\":{},\\\"Data\\\":{},\\\"OutputData\\\":{},\\\"Datacaches\\\":[],\\\"JobName\\\":null,\\\"MaxRunDurationSeconds\\\":null,\\\"NodeCount\\\":1,\\\"InstanceTypes\\\":[],\\\"Priority\\\":null,\\\"CredentialPassthrough\\\":false,\\\"Identity\\\":null,\\\"Environment\\\":{\\\"Name\\\":\\\"default-environment\\\",\\\"AutoRebuild\\\":true,\\\"Python\\\":{\\\"InterpreterPath\\\":\\\"python\\\",\\\"UserManagedDependencies\\\":true,\\\"CondaDependencies\\\":{\\\"name\\\":\\\"project_environment\\\",\\\"dependencies\\\":[\\\"python=3.8.13\\\",{\\\"pip\\\":[\\\"azureml-defaults\\\"]}],\\\"channels\\\":[\\\"anaconda\\\",\\\"conda-forge\\\"]},\\\"BaseCondaEnvironment\\\":null},\\\"EnvironmentVariables\\\":{\\\"EXAMPLE_ENV_VAR\\\":\\\"EXAMPLE_VALUE\\\"},\\\"Docker\\\":{\\\"BaseImage\\\":\\\"sklearn:0.20.3-cpu\\\",\\\"Platform\\\":{\\\"Os\\\":\\\"Linux\\\",\\\"Architecture\\\":\\\"amd64\\\"},\\\"BaseDockerfile\\\":null,\\\"BaseImageRegistry\\\":{\\\"Address\\\":\\\"viennaprivate.azurecr.io\\\",\\\"Username\\\":null,\\\"Password\\\":null},\\\"Enabled\\\":false,\\\"Arguments\\\":[]},\\\"Spark\\\":{\\\"Repositories\\\":[],\\\"Packages\\\":[],\\\"PrecachePackages\\\":false},\\\"InferencingStackVersion\\\":null},\\\"History\\\":{\\\"OutputCollection\\\":true,\\\"DirectoriesToWatch\\\":[\\\"logs\\\"],\\\"EnableMLflowTracking\\\":true,\\\"snapshotProject\\\":true},\\\"Spark\\\":{\\\"Configuration\\\":{\\\"spark.app.name\\\":\\\"Azure ML Experiment\\\",\\\"spark.yarn.maxAppAttempts\\\":\\\"1\\\"}},\\\"ParallelTask\\\":{\\\"MaxRetriesPerWorker\\\":0,\\\"WorkerCountPerNode\\\":1,\\\"TerminalExitCodes\\\":null,\\\"Configuration\\\":{}},\\\"BatchAi\\\":{\\\"NodeCount\\\":0},\\\"AmlCompute\\\":{\\\"Name\\\":null,\\\"VmSize\\\":null,\\\"RetainCluster\\\":false,\\\"ClusterMaxNodeCount\\\":1},\\\"AISuperComputer\\\":{\\\"InstanceType\\\":\\\"D2\\\",\\\"FrameworkImage\\\":null,\\\"ImageVersion\\\":null,\\\"Location\\\":null,\\\"AISuperComputerStorageData\\\":null,\\\"Interactive\\\":false,\\\"ScalePolicy\\\":null,\\\"VirtualClusterArmId\\\":null,\\\"TensorboardLogDirectory\\\":null,\\\"SSHPublicKey\\\":null,\\\"SSHPublicKeys\\\":null,\\\"EnableAzmlInt\\\":true,\\\"Priority\\\":\\\"Medium\\\",\\\"SLATier\\\":\\\"Standard\\\",\\\"UserAlias\\\":null},\\\"KubernetesCompute\\\":{\\\"InstanceType\\\":null},\\\"Tensorflow\\\":{\\\"WorkerCount\\\":1,\\\"ParameterServerCount\\\":1},\\\"Mpi\\\":{\\\"ProcessCountPerNode\\\":1},\\\"PyTorch\\\":{\\\"CommunicationBackend\\\":\\\"nccl\\\",\\\"ProcessCount\\\":null},\\\"Hdi\\\":{\\\"YarnDeployMode\\\":2},\\\"ContainerInstance\\\":{\\\"Region\\\":null,\\\"CpuCores\\\":2.0,\\\"MemoryGb\\\":3.5},\\\"ExposedPorts\\\":null,\\\"Docker\\\":{\\\"UseDocker\\\":true,\\\"SharedVolumes\\\":true,\\\"ShmSize\\\":null,\\\"Arguments\\\":[]},\\\"Cmk8sCompute\\\":{\\\"Configuration\\\":{}},\\\"CommandReturnCodeConfig\\\":{\\\"ReturnCode\\\":0,\\\"SuccessfulReturnCodes\\\":[]},\\\"EnvironmentVariables\\\":{},\\\"ApplicationEndpoints\\\":{},\\\"Parameters\\\":[]},\\\"SnapshotId\\\":\\\"dfc2537b-ca59-446a-a260-abfc5671e6b9\\\",\\\"Snapshots\\\":[],\\\"SourceCodeDataReference\\\":null,\\\"ParentRunId\\\":null,\\\"DataContainerId\\\":null,\\\"RunType\\\":null,\\\"DisplayName\\\":null,\\\"EnvironmentAssetId\\\":null,\\\"Properties\\\":{},\\\"Tags\\\":{},\\\"AggregatedArtifactPath\\\":null},\\\"ParentRunId\\\":\\\"HD_996f83d1-87a6-47f0-bbcf-e14004fb928c\\\"}\", \"_aml_system_resume_child_runs\": \"null\", \"_aml_system_all_jobs_generated\": \"true\", \"_aml_system_cancellation_requested\": \"false\", \"_aml_system_progress_metadata_evaluation_timestamp\": \"\\\"2023-06-06T15:37:21.150801\\\"\", \"_aml_system_progress_metadata_digest\": \"\\\"03ab7963cb783a5ff4e5761034785da351fd94bf36eb58e9f102a750fc4cfae6\\\"\", \"_aml_system_progress_metadata_active_timestamp\": \"\\\"2023-06-06T15:37:21.150801\\\"\", \"_aml_system_optimizer_state_artifact\": \"null\", \"_aml_system_outdated_optimizer_state_artifacts\": \"\\\"[]\\\"\", \"_aml_system_HD_996f83d1-87a6-47f0-bbcf-e14004fb928c_0\": \"{\\\"--C\\\": 0.3508204401774941, \\\"--max-iter\\\": 200}\", \"_aml_system_HD_996f83d1-87a6-47f0-bbcf-e14004fb928c_1\": \"{\\\"--C\\\": 0.1920010115679216, \\\"--max-iter\\\": 50}\", \"_aml_system_HD_996f83d1-87a6-47f0-bbcf-e14004fb928c_2\": \"{\\\"--C\\\": 0.5792893272477313, \\\"--max-iter\\\": 50}\", \"_aml_system_HD_996f83d1-87a6-47f0-bbcf-e14004fb928c_3\": \"{\\\"--C\\\": 0.5791767301113815, \\\"--max-iter\\\": 50}\", \"_aml_system_HD_996f83d1-87a6-47f0-bbcf-e14004fb928c_4\": \"{\\\"--C\\\": 0.15937261269611155, \\\"--max-iter\\\": 50}\"}, \"script_name\": null, \"arguments\": null, \"end_time_utc\": \"2023-06-06T16:02:51.616355Z\", \"status\": \"Failed\", \"log_files\": {\"azureml-logs/hyperdrive.txt\": \"https://mlstrg235168.blob.core.windows.net/azureml/ExperimentRun/dcid.HD_996f83d1-87a6-47f0-bbcf-e14004fb928c/azureml-logs/hyperdrive.txt?sv=2019-07-07&sr=b&sig=bpKYbz%2FnrNaFaLZlXYgzYMPbtc9MCPWwRtKJoUyXCB0%3D&skoid=39801763-e968-42b1-9126-7ddbc30f74c4&sktid=660b3398-b80e-49d2-bc5b-ac1dc93b5254&skt=2023-06-06T15%3A27%3A24Z&ske=2023-06-07T23%3A37%3A24Z&sks=b&skv=2019-07-07&st=2023-06-06T16%3A09%3A34Z&se=2023-06-07T00%3A19%3A34Z&sp=r\"}, \"log_groups\": [[\"azureml-logs/hyperdrive.txt\"]], \"run_duration\": \"0:26:00\", \"run_number\": \"1686065811\", \"run_queued_details\": {\"status\": \"Failed\", \"details\": null}, \"hyper_parameters\": {\"--C\": [\"uniform\", [0.01, 1.0]], \"--max-iter\": [\"choice\", [[10, 20, 50, 100, 200]]]}}, \"child_runs\": [{\"run_id\": \"HD_996f83d1-87a6-47f0-bbcf-e14004fb928c_2\", \"run_number\": 1686065812, \"metric\": null, \"status\": \"Failed\", \"run_type\": \"azureml.scriptrun\", \"training_percent\": null, \"start_time\": \"2023-06-06T16:01:13.802161Z\", \"end_time\": \"2023-06-06T16:02:11.812448Z\", \"created_time\": \"2023-06-06T15:36:52.422088Z\", \"created_time_dt\": \"2023-06-06T15:36:52.422088Z\", \"duration\": \"0:25:19\", \"hyperdrive_id\": \"996f83d1-87a6-47f0-bbcf-e14004fb928c\", \"arguments\": null, \"param_--C\": 0.5792893272477313, \"param_--max-iter\": 50}], \"children_metrics\": {\"categories\": null, \"series\": null, \"metricName\": null}, \"run_metrics\": [], \"run_logs\": \"[2023-06-06T15:36:51.554930][GENERATOR][INFO]Trying to sample '5' jobs from the hyperparameter space\\n[2023-06-06T15:36:51.9448943Z][SCHEDULER][INFO]Scheduling job, id='HD_996f83d1-87a6-47f0-bbcf-e14004fb928c_0' \\n[2023-06-06T15:36:52.0821051Z][SCHEDULER][INFO]Scheduling job, id='HD_996f83d1-87a6-47f0-bbcf-e14004fb928c_1' \\n[2023-06-06T15:36:52.2208024Z][SCHEDULER][INFO]Scheduling job, id='HD_996f83d1-87a6-47f0-bbcf-e14004fb928c_2' \\n[2023-06-06T15:36:52.4147176Z][SCHEDULER][INFO]Scheduling job, id='HD_996f83d1-87a6-47f0-bbcf-e14004fb928c_4' \\n[2023-06-06T15:36:52.3349755Z][SCHEDULER][INFO]Successfully scheduled a job. Id='HD_996f83d1-87a6-47f0-bbcf-e14004fb928c_0' \\n[2023-06-06T15:36:52.4830288Z][SCHEDULER][INFO]Successfully scheduled a job. Id='HD_996f83d1-87a6-47f0-bbcf-e14004fb928c_2' \\n[2023-06-06T15:36:52.354584][GENERATOR][INFO]Successfully sampled '5' jobs, they will soon be submitted to the execution target.\\n[2023-06-06T15:36:52.3157384Z][SCHEDULER][INFO]Scheduling job, id='HD_996f83d1-87a6-47f0-bbcf-e14004fb928c_3' \\n[2023-06-06T15:36:52.5337595Z][SCHEDULER][INFO]Successfully scheduled a job. Id='HD_996f83d1-87a6-47f0-bbcf-e14004fb928c_3' \\n[2023-06-06T15:36:52.5742371Z][SCHEDULER][INFO]Successfully scheduled a job. Id='HD_996f83d1-87a6-47f0-bbcf-e14004fb928c_1' \\n[2023-06-06T15:36:52.6449623Z][SCHEDULER][INFO]Successfully scheduled a job. Id='HD_996f83d1-87a6-47f0-bbcf-e14004fb928c_4' \\n[2023-06-06T15:37:22.163611][GENERATOR][INFO]Max number of jobs '5' reached for experiment.\\n[2023-06-06T15:37:22.272950][GENERATOR][INFO]All jobs generated.\\n[2023-06-06T16:02:51.379876][CONTROLLER][INFO]Experiment has been marked for failure.\\n[2023-06-06T16:02:51.379933][CONTROLLER][WARNING]User errors were found in at least one of the child runs.\\n[2023-06-06T16:02:51.848168][CONTROLLER][INFO]Experiment was 'ExperimentStatus.RUNNING', is 'ExperimentStatus.FAILED'.\\n\\nError occurred: Execution failed. User process 'python' exited with status code 2. Please check log file 'user_logs/std_log.txt' for error details. Error: Traceback (most recent call last):\\n  File \\\"train.py\\\", line 77, in <module>\\n    main()\\n  File \\\"train.py\\\", line 47, in main\\n    args = parser.parse_args()\\n  File \\\"/opt/miniconda/lib/python3.6/argparse.py\\\", line 1733, in parse_args\\n    self.error(msg % ' '.join(argv))\\n  File \\\"/opt/miniconda/lib/python3.6/argparse.py\\\", line 2389, in error\\n    self.exit(2, _('%(prog)s: error: %(message)s\\\\n') % args)\\n  File \\\"/opt/miniconda/lib/python3.6/argparse.py\\\", line 2376, in exit\\n    _sys.exit(status)\\nSystemExit: 2\\n\\n\\n\", \"graph\": {}, \"widget_settings\": {\"childWidgetDisplay\": \"popup\", \"send_telemetry\": false, \"log_level\": \"INFO\", \"sdk_version\": \"1.49.0\"}, \"loading\": false}"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "RunId: HD_996f83d1-87a6-47f0-bbcf-e14004fb928c\nWeb View: https://ml.azure.com/runs/HD_996f83d1-87a6-47f0-bbcf-e14004fb928c?wsid=/subscriptions/9a7511b8-150f-4a58-8528-3e7d50216c31/resourcegroups/aml-quickstarts-235168/workspaces/quick-starts-ws-235168&tid=660b3398-b80e-49d2-bc5b-ac1dc93b5254\n\nStreaming azureml-logs/hyperdrive.txt\n=====================================\n\n[2023-06-06T15:36:51.554930][GENERATOR][INFO]Trying to sample '5' jobs from the hyperparameter space\n[2023-06-06T15:36:51.9448943Z][SCHEDULER][INFO]Scheduling job, id='HD_996f83d1-87a6-47f0-bbcf-e14004fb928c_0' \n[2023-06-06T15:36:52.0821051Z][SCHEDULER][INFO]Scheduling job, id='HD_996f83d1-87a6-47f0-bbcf-e14004fb928c_1' \n[2023-06-06T15:36:52.2208024Z][SCHEDULER][INFO]Scheduling job, id='HD_996f83d1-87a6-47f0-bbcf-e14004fb928c_2' \n[2023-06-06T15:36:52.4147176Z][SCHEDULER][INFO]Scheduling job, id='HD_996f83d1-87a6-47f0-bbcf-e14004fb928c_4' \n[2023-06-06T15:36:52.3349755Z][SCHEDULER][INFO]Successfully scheduled a job. Id='HD_996f83d1-87a6-47f0-bbcf-e14004fb928c_0' \n[2023-06-06T15:36:52.4830288Z][SCHEDULER][INFO]Successfully scheduled a job. Id='HD_996f83d1-87a6-47f0-bbcf-e14004fb928c_2' \n[2023-06-06T15:36:52.354584][GENERATOR][INFO]Successfully sampled '5' jobs, they will soon be submitted to the execution target.\n[2023-06-06T15:36:52.3157384Z][SCHEDULER][INFO]Scheduling job, id='HD_996f83d1-87a6-47f0-bbcf-e14004fb928c_3' \n[2023-06-06T15:36:52.5337595Z][SCHEDULER][INFO]Successfully scheduled a job. Id='HD_996f83d1-87a6-47f0-bbcf-e14004fb928c_3' \n[2023-06-06T15:36:52.5742371Z][SCHEDULER][INFO]Successfully scheduled a job. Id='HD_996f83d1-87a6-47f0-bbcf-e14004fb928c_1' \n[2023-06-06T15:36:52.6449623Z][SCHEDULER][INFO]Successfully scheduled a job. Id='HD_996f83d1-87a6-47f0-bbcf-e14004fb928c_4' \n[2023-06-06T15:37:22.163611][GENERATOR][INFO]Max number of jobs '5' reached for experiment.\n[2023-06-06T15:37:22.272950][GENERATOR][INFO]All jobs generated.\n[2023-06-06T16:02:51.379876][CONTROLLER][INFO]Experiment has been marked for failure.\n[2023-06-06T16:02:51.379933][CONTROLLER][WARNING]User errors were found in at least one of the child runs.\n[2023-06-06T16:02:51.848168][CONTROLLER][INFO]Experiment was 'ExperimentStatus.RUNNING', is 'ExperimentStatus.FAILED'.\n\nExecution Summary\n=================\nRunId: HD_996f83d1-87a6-47f0-bbcf-e14004fb928c\nWeb View: https://ml.azure.com/runs/HD_996f83d1-87a6-47f0-bbcf-e14004fb928c?wsid=/subscriptions/9a7511b8-150f-4a58-8528-3e7d50216c31/resourcegroups/aml-quickstarts-235168/workspaces/quick-starts-ws-235168&tid=660b3398-b80e-49d2-bc5b-ac1dc93b5254\n\nWarnings:\nExecution failed. User process 'python' exited with status code 2. Please check log file 'user_logs/std_log.txt' for error details. Error: Traceback (most recent call last):\n  File \"train.py\", line 77, in <module>\n    main()\n  File \"train.py\", line 47, in\n\n"
        },
        {
          "output_type": "error",
          "ename": "ActivityFailedException",
          "evalue": "ActivityFailedException:\n\tMessage: Activity Failed:\n{\n    \"error\": {\n        \"code\": \"UserError\",\n        \"message\": \"Execution failed. User process 'python' exited with status code 2. Please check log file 'user_logs/std_log.txt' for error details. Error: Traceback (most recent call last):\\n  File \\\"train.py\\\", line 77, in <module>\\n    main()\\n  File \\\"train.py\\\", line 47, in main\\n    args = parser.parse_args()\\n  File \\\"/opt/miniconda/lib/python3.6/argparse.py\\\", line 1733, in parse_args\\n    self.error(msg % ' '.join(argv))\\n  File \\\"/opt/miniconda/lib/python3.6/argparse.py\\\", line 2389, in error\\n    self.exit(2, _('%(prog)s: error: %(message)s\\\\n') % args)\\n  File \\\"/opt/miniconda/lib/python3.6/argparse.py\\\", line 2376, in exit\\n    _sys.exit(status)\\nSystemExit: 2\\n\\n\",\n        \"messageParameters\": {},\n        \"details\": []\n    },\n    \"time\": \"0001-01-01T00:00:00.000Z\"\n}\n\tInnerException None\n\tErrorResponse \n{\n    \"error\": {\n        \"message\": \"Activity Failed:\\n{\\n    \\\"error\\\": {\\n        \\\"code\\\": \\\"UserError\\\",\\n        \\\"message\\\": \\\"Execution failed. User process 'python' exited with status code 2. Please check log file 'user_logs/std_log.txt' for error details. Error: Traceback (most recent call last):\\\\n  File \\\\\\\"train.py\\\\\\\", line 77, in <module>\\\\n    main()\\\\n  File \\\\\\\"train.py\\\\\\\", line 47, in main\\\\n    args = parser.parse_args()\\\\n  File \\\\\\\"/opt/miniconda/lib/python3.6/argparse.py\\\\\\\", line 1733, in parse_args\\\\n    self.error(msg % ' '.join(argv))\\\\n  File \\\\\\\"/opt/miniconda/lib/python3.6/argparse.py\\\\\\\", line 2389, in error\\\\n    self.exit(2, _('%(prog)s: error: %(message)s\\\\\\\\n') % args)\\\\n  File \\\\\\\"/opt/miniconda/lib/python3.6/argparse.py\\\\\\\", line 2376, in exit\\\\n    _sys.exit(status)\\\\nSystemExit: 2\\\\n\\\\n\\\",\\n        \\\"messageParameters\\\": {},\\n        \\\"details\\\": []\\n    },\\n    \\\"time\\\": \\\"0001-01-01T00:00:00.000Z\\\"\\n}\"\n    }\n}",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mActivityFailedException\u001b[0m                   Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[4], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m hyperdrive_run \u001b[38;5;241m=\u001b[39m exp\u001b[38;5;241m.\u001b[39msubmit(config\u001b[38;5;241m=\u001b[39mhyperdrive_config)\n\u001b[1;32m      5\u001b[0m RunDetails(hyperdrive_run)\u001b[38;5;241m.\u001b[39mshow()\n\u001b[0;32m----> 6\u001b[0m \u001b[43mhyperdrive_run\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait_for_completion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshow_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/core/run.py:849\u001b[0m, in \u001b[0;36mRun.wait_for_completion\u001b[0;34m(self, show_output, wait_post_processing, raise_on_error)\u001b[0m\n\u001b[1;32m    847\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m show_output:\n\u001b[1;32m    848\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 849\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stream_run_output\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    850\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfile_handle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstdout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    851\u001b[0m \u001b[43m            \u001b[49m\u001b[43mwait_post_processing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwait_post_processing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    852\u001b[0m \u001b[43m            \u001b[49m\u001b[43mraise_on_error\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mraise_on_error\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    853\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_details()\n\u001b[1;32m    854\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/core/run.py:1102\u001b[0m, in \u001b[0;36mRun._stream_run_output\u001b[0;34m(self, file_handle, wait_post_processing, raise_on_error)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         file_handle\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1101\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1102\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ActivityFailedException(error_details\u001b[38;5;241m=\u001b[39mjson\u001b[38;5;241m.\u001b[39mdumps(error, indent\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m))\n\u001b[1;32m   1104\u001b[0m file_handle\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1105\u001b[0m file_handle\u001b[38;5;241m.\u001b[39mflush()\n",
            "\u001b[0;31mActivityFailedException\u001b[0m: ActivityFailedException:\n\tMessage: Activity Failed:\n{\n    \"error\": {\n        \"code\": \"UserError\",\n        \"message\": \"Execution failed. User process 'python' exited with status code 2. Please check log file 'user_logs/std_log.txt' for error details. Error: Traceback (most recent call last):\\n  File \\\"train.py\\\", line 77, in <module>\\n    main()\\n  File \\\"train.py\\\", line 47, in main\\n    args = parser.parse_args()\\n  File \\\"/opt/miniconda/lib/python3.6/argparse.py\\\", line 1733, in parse_args\\n    self.error(msg % ' '.join(argv))\\n  File \\\"/opt/miniconda/lib/python3.6/argparse.py\\\", line 2389, in error\\n    self.exit(2, _('%(prog)s: error: %(message)s\\\\n') % args)\\n  File \\\"/opt/miniconda/lib/python3.6/argparse.py\\\", line 2376, in exit\\n    _sys.exit(status)\\nSystemExit: 2\\n\\n\",\n        \"messageParameters\": {},\n        \"details\": []\n    },\n    \"time\": \"0001-01-01T00:00:00.000Z\"\n}\n\tInnerException None\n\tErrorResponse \n{\n    \"error\": {\n        \"message\": \"Activity Failed:\\n{\\n    \\\"error\\\": {\\n        \\\"code\\\": \\\"UserError\\\",\\n        \\\"message\\\": \\\"Execution failed. User process 'python' exited with status code 2. Please check log file 'user_logs/std_log.txt' for error details. Error: Traceback (most recent call last):\\\\n  File \\\\\\\"train.py\\\\\\\", line 77, in <module>\\\\n    main()\\\\n  File \\\\\\\"train.py\\\\\\\", line 47, in main\\\\n    args = parser.parse_args()\\\\n  File \\\\\\\"/opt/miniconda/lib/python3.6/argparse.py\\\\\\\", line 1733, in parse_args\\\\n    self.error(msg % ' '.join(argv))\\\\n  File \\\\\\\"/opt/miniconda/lib/python3.6/argparse.py\\\\\\\", line 2389, in error\\\\n    self.exit(2, _('%(prog)s: error: %(message)s\\\\\\\\n') % args)\\\\n  File \\\\\\\"/opt/miniconda/lib/python3.6/argparse.py\\\\\\\", line 2376, in exit\\\\n    _sys.exit(status)\\\\nSystemExit: 2\\\\n\\\\n\\\",\\n        \\\"messageParameters\\\": {},\\n        \\\"details\\\": []\\n    },\\n    \\\"time\\\": \\\"0001-01-01T00:00:00.000Z\\\"\\n}\"\n    }\n}"
          ]
        }
      ],
      "execution_count": 4,
      "metadata": {
        "gather": {
          "logged": 1686067394265
        }
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "# Get your best run and save the model from that run.\n",
        "\n",
        "### YOUR CODE HERE ###\n",
        "best_run = hyperdrive_run.get_best_run_by_primary_metric()\n",
        "best_run_metrics = best_run.get_metrics()\n",
        "\n",
        "print(f\"Best run id: {best_run.id}\")\n",
        "print(f\"Best run accuracy: {best_run_metrics['Accuracy']}\")"
      ],
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'NoneType' object has no attribute 'get_metrics'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[5], line 6\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# Get your best run and save the model from that run.\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m### YOUR CODE HERE ###\u001b[39;00m\n\u001b[1;32m      5\u001b[0m best_run \u001b[38;5;241m=\u001b[39m hyperdrive_run\u001b[38;5;241m.\u001b[39mget_best_run_by_primary_metric()\n\u001b[0;32m----> 6\u001b[0m best_run_metrics \u001b[38;5;241m=\u001b[39m \u001b[43mbest_run\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_metrics\u001b[49m()\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest run id: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbest_run\u001b[38;5;241m.\u001b[39mid\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest run accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbest_run_metrics[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'get_metrics'"
          ]
        }
      ],
      "execution_count": 5,
      "metadata": {
        "gather": {
          "logged": 1686067566319
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_run.get_file_names()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_run.download_files()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = best_run.register_model(\r\n",
        "    model_name=\"model.joblib\",\r\n",
        "    model_path=\"outputs/model.joblib\"\r\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## AutoML"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.data.dataset_factory import TabularDatasetFactory\n",
        "\n",
        "# Create TabularDataset using TabularDatasetFactory\n",
        "# Data is available at: \n",
        "# \"https://automlsamplenotebookdata.blob.core.windows.net/automl-sample-notebook-data/bankmarketing_train.csv\"\n",
        "\n",
        "### YOUR CODE HERE ###\n",
        "data_url = \"https://automlsamplenotebookdata.blob.core.windows.net/automl-sample-notebook-data/bankmarketing_train.csv\"\n",
        "dataset = TabularDatasetFactory.from_delimited_files(path=data_url)"
      ],
      "outputs": [],
      "execution_count": 6,
      "metadata": {
        "gather": {
          "logged": 1686067778821
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from train import clean_data\n",
        "\n",
        "# Use the clean_data function to clean your data.\n",
        "x, y = clean_data(dataset)"
      ],
      "outputs": [],
      "execution_count": 7,
      "metadata": {
        "gather": {
          "logged": 1686067795679
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Add target to x dataframe\r\n",
        "x[\"y\"] = y"
      ],
      "outputs": [],
      "execution_count": 9,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1686067818651
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "datastore = ws.get_default_datastore()\r\n",
        "train_dataset = TabularDatasetFactory.register_pandas_dataframe(\r\n",
        "    dataframe=x,\r\n",
        "    target=datastore,\r\n",
        "    name=\"train_dataset\"\r\n",
        ")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Validating arguments.\nArguments validated.\nSuccessfully obtained datastore reference and path.\nUploading file to managed-dataset/f3002977-e2c0-423c-a04e-f7e820051c56/\nColumn header contains '.' This period will be translated to '_' as we write the data out to parquet files: 'emp.var.rate' -> 'emp_var_rate'\nColumn header contains '.' This period will be translated to '_' as we write the data out to parquet files: 'cons.price.idx' -> 'cons_price_idx'\nColumn header contains '.' This period will be translated to '_' as we write the data out to parquet files: 'cons.conf.idx' -> 'cons_conf_idx'\nColumn header contains '.' This period will be translated to '_' as we write the data out to parquet files: 'nr.employed' -> 'nr_employed'\nColumn header contains '.' This period will be translated to '_' as we write the data out to parquet files: 'job_admin.' -> 'job_admin_'\nColumn header contains '.' This period will be translated to '_' as we write the data out to parquet files: 'education_basic.4y' -> 'education_basic_4y'\nColumn header contains '.' This period will be translated to '_' as we write the data out to parquet files: 'education_basic.6y' -> 'education_basic_6y'\nColumn header contains '.' This period will be translated to '_' as we write the data out to parquet files: 'education_basic.9y' -> 'education_basic_9y'\nColumn header contains '.' This period will be translated to '_' as we write the data out to parquet files: 'education_high.school' -> 'education_high_school'\nColumn header contains '.' This period will be translated to '_' as we write the data out to parquet files: 'education_professional.course' -> 'education_professional_course'\nColumn header contains '.' This period will be translated to '_' as we write the data out to parquet files: 'education_university.degree' -> 'education_university_degree'\nSuccessfully uploaded file to datastore.\nCreating and registering a new dataset.\nSuccessfully created and registered a new dataset.\n"
        }
      ],
      "execution_count": 12,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1686068354034
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.train.automl import AutoMLConfig\n",
        "\n",
        "# Set parameters for AutoMLConfig\n",
        "# NOTE: DO NOT CHANGE THE experiment_timeout_minutes PARAMETER OR YOUR INSTANCE WILL TIME OUT.\n",
        "# If you wish to run the experiment longer, you will need to run this notebook in your own\n",
        "# Azure tenant, which will incur personal costs.\n",
        "automl_config = AutoMLConfig(\n",
        "    experiment_timeout_minutes=30,\n",
        "    task=\"classification\",\n",
        "    primary_metric=\"accuracy\",\n",
        "    training_data=train_dataset,\n",
        "    label_column_name=\"y\",\n",
        "    n_cross_validations=5,\n",
        "    compute_target=compute_target\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 13,
      "metadata": {
        "gather": {
          "logged": 1686068476329
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Submit your automl run\n",
        "\n",
        "### YOUR CODE HERE ###\n",
        "automl_run = exp.submit(config=automl_config)\n",
        "RunDetails(automl_run).show()\n",
        "automl_run.wait_for_completion(show_output=True)"
      ],
      "outputs": [],
      "execution_count": 2,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Retrieve and save your best automl model.\n",
        "\n",
        "### YOUR CODE HERE ###\n",
        "best_automl_run, best_automl_model = automl_run.get_output()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "best_automl_run.register_model(\r\n",
        "    model_name=\"model.pkl\",\r\n",
        "    model_path=\"./outputs\"\r\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Clean up\r\n",
        "compute_target.delete()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python38-azureml"
    },
    "kernelspec": {
      "name": "python38-azureml",
      "language": "python",
      "display_name": "Python 3.8 - AzureML"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.5",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}